# Chandra OCR Deployment on Nibi - Summary

**Date:** November 1, 2025
**Status:** ‚úÖ Successfully Deployed and Tested
**Repository:** https://github.com/jburnford/chandra-ocr

## Overview

Successfully deployed Chandra OCR (high-accuracy VLM-based OCR model) on Nibi cluster with H100 GPU support. Completed initial testing and launched batch processing of two historical document collections totaling 700 documents.

## Architecture

### Model Information
- **Model:** Chandra (datalab-to/chandra) - Qwen3 VL 7B based OCR model
- **Performance:** 83.1% accuracy on OLMoCR benchmark (vs 69.9% for GPT-4o)
- **Cost:** ~$190 per million pages (97% cheaper than GPT-4o at $6,200/M)
- **Model Size:** ~15-20GB cached

### Infrastructure Setup
- **Cluster:** Nibi (Compute Canada)
- **GPU:** NVIDIA H100 80GB HBM3
- **Python:** 3.12
- **CUDA:** 12.2
- **Additional Modules:** gcc, arrow/18.1.0
- **Virtual Environment:** `/home/jic823/projects/def-jic823/chandra-ocr/.venv/`
- **Model Cache:** `/home/jic823/projects/def-jic823/.cache/huggingface/` (project space to avoid home quota)

## Installation Process

### Initial Setup Issues Resolved

1. **CUDA Version Compatibility**
   - Initial script used CUDA 12.1 (not available)
   - Fixed: Updated to CUDA 12.2

2. **Arrow Module Version**
   - Initial script used arrow/18.0.0 (not available)
   - Fixed: Updated to arrow/18.1.0

3. **Dependency Issues**
   - `hf-xet` required Rust compiler (not available)
   - Fixed: Installed chandra with `--no-deps`, then installed dependencies individually

4. **PyTorch Version Conflict**
   - Flash-attention downgraded torch from 2.9 to 2.7.1
   - Caused torchvision incompatibility
   - Fixed: Reinstalled correct torch/torchvision versions after flash-attn

5. **Disk Quota Issue**
   - Home directory over quota (75GB/50GB used)
   - Model download failed due to space
   - Fixed: Moved HuggingFace cache to project space via `HF_HOME` and `TRANSFORMERS_CACHE` environment variables

6. **Path Expansion in SLURM**
   - Tilde (`~`) not expanding in script context
   - Fixed: Used absolute paths instead

### Final Working Configuration

**Setup Script:** `nibi_setup.sh`
```bash
module load python/3.12 cuda/12.2 gcc arrow/18.1.0
python3 -m venv ~/projects/def-jic823/chandra-ocr/.venv
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
pip install -e . --no-deps
pip install [dependencies individually, skipping hf-xet]
pip install flash-attn --no-build-isolation
pip install --force-reinstall --no-deps torch torchvision
```

**Runtime Configuration:**
```bash
export HF_HOME=/home/jic823/projects/def-jic823/.cache/huggingface
export TRANSFORMERS_CACHE=/home/jic823/projects/def-jic823/.cache/huggingface
```

## Performance Testing

### Initial Single-Page Test
- **Document:** 3200797032.pdf (879KB, 1 page)
- **Model Load Time:** ~4 minutes (first time download)
- **Processing Time:** ~1 minute per page
- **Total Time:** ~5 minutes
- **Output Quality:** ‚úÖ Excellent - accurate text extraction with preserved structure

### Batch Processing Performance - Simple Documents
- **Actual Rate:** 2.5-4 PDFs/minute (much faster than initial estimates)
- **GPU:** H100 fully utilized
- **Batch Processing:** Sequential (batch-size=1 for stability)

### Multi-Page Table-Heavy Documents (November 1, 2025)
**CRITICAL FINDING:** Processing speed is **significantly slower** for documents with complex tables and layouts.

#### Test Documents
1. **1862 Annual Statement of Trade and Navigation** (498 pages)
   - Processing speed: **~0.7 pages/minute**
   - Estimated total time: **~12 hours** for 498 pages
   - Job ID: 3789620 (16-hour time limit)

2. **Blue Book Gold Coast 1922** (700 pages)
   - Processing speed: **~1.4 pages/minute**
   - Estimated total time: **~8 hours** for 700 pages
   - Job ID: 3772610 (12-hour time limit)

#### Performance Comparison
| Document Type | Pages/Minute | Speedup vs Tables |
|--------------|--------------|-------------------|
| Simple single-page PDFs (British Library) | 4.0 | 5.7x faster |
| Historical images (Jacob Gold) | 2.9 | 4.1x faster |
| Table-heavy documents (Blue Book) | 1.4 | baseline |
| Very complex tables (1862 Trade) | 0.7 | 0.5x (2x slower) |

#### Key Learnings
- ‚ö†Ô∏è **Table complexity matters**: Documents with dense tables process 4-6x slower than simple text
- ‚ö†Ô∏è **Time estimates crucial**: Always allocate 12-16 hours for 500+ page table-heavy documents
- ‚ö†Ô∏è **No incremental saves**: Chandra accumulates ALL results in memory and writes only at completion
  - **If job times out, ALL progress is lost** - no partial results saved
  - Critical to set sufficient time limits on first submission
- ‚úÖ **Model loading overhead**: Only ~60 seconds, negligible for long jobs

## Batch Jobs Completed/Running

### 1. Jacob Gold Corpus - ‚úÖ COMPLETED
- **Job ID:** 3759963
- **Status:** Completed successfully
- **Documents:** 100 historical document page images (JPG)
- **Collection:** Caribbean historical documents (1614-1807)
- **Time:** 34 minutes
- **Output:** `/home/jic823/projects/def-jic823/jacob_gold_output/`
- **Size:** 1.2MB

### 2. British Library BLN600 Collection - üîÑ IN PROGRESS
- **Job ID:** 3759808
- **Status:** Running (453/600 completed - 75.5%)
- **Documents:** 600 single-page PDFs from British Library digitization
- **Time Elapsed:** ~3 hours
- **ETA:** ~1 hour remaining
- **Output:** `/home/jic823/projects/def-jic823/british_library_output/`

## Output Format

For each processed document, Chandra creates:
```
output_directory/
‚îú‚îÄ‚îÄ [document_name]/
‚îÇ   ‚îú‚îÄ‚îÄ [document_name].md              # Markdown text
‚îÇ   ‚îú‚îÄ‚îÄ [document_name].html            # HTML formatted output
‚îÇ   ‚îú‚îÄ‚îÄ [document_name]_metadata.json   # Processing metadata
‚îÇ   ‚îî‚îÄ‚îÄ images/                         # Extracted images (if any)
```

### Metadata JSON Structure
```json
{
  "file_name": "filename.pdf",
  "num_pages": 1,
  "total_token_count": 445,
  "total_chunks": 2,
  "total_images": 0,
  "pages": [
    {
      "page_num": 0,
      "page_box": [0, 0, 2112, 2787],  // Page dimensions only
      "token_count": 445,
      "num_chunks": 2,
      "num_images": 0
    }
  ]
}
```

**Note:** Chandra provides page-level bounding boxes but **NOT word-level or character-level coordinates**. Use alternative OCR tools (Tesseract hOCR, OLMoCR, etc.) if spatial information is required.

## Recommended Time Limits

**CRITICAL:** Since Chandra saves results only after processing ALL pages, setting adequate time limits is essential to avoid data loss.

### Time Limit Guidelines by Document Type

| Document Type | Processing Speed | Example Time Limits |
|--------------|------------------|---------------------|
| Simple single-page PDFs | 4 pages/min | 100 pages ‚Üí 30 min, 600 pages ‚Üí 3 hours |
| Historical images | 2.9 pages/min | 100 pages ‚Üí 45 min, 600 pages ‚Üí 4 hours |
| Table-heavy documents | 1.4 pages/min | 500 pages ‚Üí 6 hours, 700 pages ‚Üí 9 hours |
| Very complex tables | 0.7 pages/min | 500 pages ‚Üí 12 hours, 1000 pages ‚Üí 24 hours |

### Recommended Approach
1. **Add 20% buffer** to calculated time (e.g., 10 hours needed ‚Üí request 12 hours)
2. **For unknown documents**: Start with small sample (10-20 pages, 1-hour limit)
3. **Measure actual speed**: Check pages/minute after 30 minutes of processing
4. **Extrapolate full time**: `(total_pages / observed_rate) √ó 1.2`
5. **Cannot extend running jobs**: Must cancel and restart with longer limit

### SLURM Time Limit Syntax
```bash
sbatch --time=12:00:00  # 12 hours
sbatch --time=24:00:00  # 24 hours (max on most clusters)
```

## Repository Structure

```
chandra-ocr/
‚îú‚îÄ‚îÄ nibi_setup.sh                      # Initial environment setup
‚îú‚îÄ‚îÄ nibi_run_chandra.slurm             # Single PDF/directory processing
‚îú‚îÄ‚îÄ nibi_vllm_server.slurm             # vLLM inference server (optional)
‚îú‚îÄ‚îÄ nibi_batch_process_bl.slurm        # British Library batch script
‚îú‚îÄ‚îÄ nibi_batch_process_jacob.slurm     # Jacob Gold corpus batch script
‚îú‚îÄ‚îÄ NIBI_DEPLOYMENT.md                 # Detailed deployment guide
‚îú‚îÄ‚îÄ QUICKSTART.md                      # Quick reference guide
‚îú‚îÄ‚îÄ DEPLOYMENT_SUMMARY.md              # This file
‚îî‚îÄ‚îÄ chandra/                           # Source code
```

## Scripts and Usage

### 1. Initial Setup (One-time)
```bash
cd ~/projects/def-jic823/chandra-ocr
bash nibi_setup.sh
# Takes ~15-20 minutes
```

### 2. Process Single Document
```bash
sbatch nibi_run_chandra.slurm <input.pdf> <output_dir>
```

### 3. Process Directory of Documents
```bash
sbatch nibi_run_chandra.slurm <input_directory> <output_dir>
```

### 4. Configuration Options (Environment Variables)
```bash
METHOD=hf                    # or vllm
PAGE_RANGE="1-10"           # Optional: specific pages
MAX_TOKENS=12384            # Max output tokens per page
INCLUDE_IMAGES=true         # Extract images
BATCH_SIZE=1                # Pages per batch
```

## Key Learnings

### What Works Well
1. ‚úÖ **High Accuracy:** Excellent text extraction quality on historical documents
2. ‚úÖ **Batch Processing:** Can process hundreds of documents efficiently
3. ‚úÖ **GPU Utilization:** H100 handles the workload well
4. ‚úÖ **Model Caching:** Subsequent runs start immediately (no redownload)
5. ‚úÖ **Structured Output:** Clean markdown/HTML preserves document structure

### Limitations
1. ‚ùå **No Word-Level Coordinates:** Only page-level bounding boxes
2. ‚ùå **No Incremental Saves:** All results held in memory until completion
   - Job timeout = total data loss
   - Must set adequate time limits from the start
3. ‚ö†Ô∏è **Sequential Processing:** No built-in parallelization (batch-size=1 for stability)
4. ‚ö†Ô∏è **Table Processing Speed:** 4-6x slower than simple text documents
5. ‚ö†Ô∏è **Home Quota Sensitivity:** Must use project space for model cache
6. ‚ö†Ô∏è **Path Expansion:** SLURM requires absolute paths (no tilde)

### Cost Considerations
- **Home Directory Space:** Models use 8-15GB (use project space!)
- **Processing Cost:** ~$190 per million pages (based on GPU time estimates)
- **Time:** ~2.5-4 pages/minute on H100

## Disk Space Management

### Issue Identified
- Home directory over quota: 75GB/50GB used
- Primary culprit: `~/.cache/huggingface/` (36GB)
  - olmOCR-7B: 9.4GB
  - Chandra (incomplete): 8.1GB (deleted)
  - DeepSeek-OCR: 6.3GB
  - PDF-Extract-Kit: 2.0GB
  - Other models: ~9GB

### Resolution
1. ‚úÖ Deleted incomplete Chandra model from home (freed 8GB)
2. ‚úÖ New downloads go to project space
3. ‚ö†Ô∏è Still over quota by ~17GB (kept other OCR models)

### Current Status
- Home: 67GB/50GB (over by 17GB, but within 71GB hard limit)
- Project space: Using for new model cache

## Future Testing Recommendations

### Performance Optimization
1. **Test vLLM Server Mode**
   - May enable parallel processing
   - Could improve throughput for large batches
   - Use `nibi_vllm_server.slurm` and `--method vllm`

2. **Batch Size Tuning**
   - Current: `BATCH_SIZE=1`
   - Test: `BATCH_SIZE=4` or `BATCH_SIZE=8`
   - May improve throughput if stable

3. **Multi-GPU Testing**
   - Request multiple H100s
   - Process multiple collections in parallel

### Quality Evaluation
1. **Compare with OLMoCR**
   - You already have olmOCR results for some documents
   - Compare accuracy, speed, output format

2. **Benchmark Against Ground Truth**
   - Use Jacob Gold corpus (may have transcriptions?)
   - Calculate WER/CER metrics

3. **Test Edge Cases**
   - Handwritten documents
   - Multi-column layouts
   - Tables and forms
   - Math equations
   - Non-English text

### Additional Collections
1. **Colonial Office Lists** (you have 163 PDFs ready)
   - Location: `~/projects/def-jic823/olmocr/canadiana_pdfs/`
   - Multi-page documents (e.g., 791 pages in ColonialOfficeList1896.pdf)

2. **Other Historical Collections**
   - Scale testing with larger batches
   - Different document types (newspapers, manuscripts, etc.)

### Coordinate Extraction
If word-level coordinates are needed:
1. **Test OLMoCR Output Format**
   - Check if it provides bounding boxes
   - Compare with Chandra for quality vs. features trade-off

2. **Pipeline Approach**
   - Use Chandra for text extraction
   - Use Tesseract/other tool for layout analysis
   - Merge results for best of both

## Troubleshooting Reference

### Common Issues

**1. "Disk quota exceeded"**
```bash
# Check quota
quota -s
# Move cache to project space (already done in scripts)
export HF_HOME=/home/jic823/projects/def-jic823/.cache/huggingface
```

**2. "CUDA not available"**
```bash
# Verify modules
module list
# Should see: python/3.12, cuda/12.2, gcc, arrow/18.1.0
```

**3. "Path does not exist" in SLURM**
```bash
# Use absolute paths, not ~
INPUT_DIR="/home/jic823/path/to/files"  # Good
INPUT_DIR="~/path/to/files"             # Bad
```

**4. "torch version incompatible"**
```bash
# Reinstall correct versions
pip install --force-reinstall --no-deps torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

## Monitoring and Management

### Check Job Status
```bash
ssh nibi squeue -u jic823
```

### View Job Output (Live)
```bash
ssh nibi tail -f ~/projects/def-jic823/chandra-ocr/chandra-*-JOBID.out
```

### Check Processing Progress
```bash
# Count completed documents
ssh nibi "ls ~/projects/def-jic823/british_library_output/ | wc -l"
```

### Cancel Job
```bash
ssh nibi scancel JOBID
```

### Download Results
```bash
scp -r nibi:/home/jic823/projects/def-jic823/jacob_gold_output /local/path/
```

## Success Metrics

### Completed
- ‚úÖ Chandra installed and tested on Nibi
- ‚úÖ Model cached in project space (avoiding quota issues)
- ‚úÖ Single document test successful
- ‚úÖ Jacob Gold corpus: 100/100 documents processed
- ‚úÖ British Library: 453/600 documents processed (ongoing)
- ‚úÖ Documentation created
- ‚úÖ Batch processing scripts validated

### Performance Achieved
- **Throughput:** 2.5-4 documents/minute
- **Accuracy:** High quality text extraction (visual inspection)
- **Stability:** No crashes, no errors in 500+ documents processed
- **Cost Efficiency:** Significantly cheaper than commercial APIs

## Next Steps

1. **Complete British Library Processing**
   - Monitor remaining ~1 hour
   - Verify all 600 PDFs processed successfully
   - Download and review sample outputs

2. **Quality Assessment**
   - Compare Chandra vs OLMoCR outputs
   - Evaluate accuracy on historical documents
   - Determine best tool for different document types

3. **Scale Testing**
   - Process Colonial Office Lists (larger multi-page documents)
   - Test with different batch sizes
   - Optimize processing parameters

4. **Production Pipeline**
   - Determine if Chandra meets requirements for word coordinates
   - Consider hybrid approach (Chandra + coordinate extraction tool)
   - Set up automated processing workflow

## Contact & Support

**Repository Issues:** https://github.com/jburnford/chandra-ocr/issues
**Upstream Project:** https://github.com/datalab-to/chandra
**Documentation:** See NIBI_DEPLOYMENT.md and QUICKSTART.md in repository

---

**Last Updated:** November 1, 2025
**Deployment Status:** ‚úÖ Production Ready
